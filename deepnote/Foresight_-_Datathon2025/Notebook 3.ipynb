{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "4cc314c0",
        "execution_start": 1763254512716,
        "execution_millis": 2470,
        "execution_context_id": "714ea9a7-d378-47be-8026-5fa12b4864af",
        "deepnote_app_block_order": 0,
        "deepnote_app_block_visible": true,
        "deepnote_app_block_group_id": null,
        "deepnote_app_is_code_hidden": true,
        "deepnote_app_is_output_hidden": false,
        "cell_id": "adb707e4570641e78ef0e294a52b8f0c",
        "deepnote_cell_type": "code"
      },
      "source": "import pandas as pd\nimport joblib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Load the dataset\ntry:\n    df = pd.read_csv(\"Health_Risk_Dataset.csv\")\nexcept FileNotFoundError:\n    print(\"Error: Health_Risk_Dataset.csv not found.\")\n    exit()\n\nprint(\"Dataset loaded successfully. Here's the info:\")\ndf.info()\n\nprint(\"\\nFirst 5 rows of the dataset:\")\nprint(df.head())\n\n# --- 1. Preprocessing ---\n\n# Drop Patient_ID as it's not a predictive feature\nif 'Patient_ID' in df.columns:\n    df = df.drop('Patient_ID', axis=1)\n\n# One-Hot Encoding for 'Consciousness'\n# Using pd.get_dummies\ndf = pd.get_dummies(df, columns=['Consciousness'], drop_first=True) # drop_first=True to avoid multicollinearity\n\n# Label Encoding for the target variable 'Risk_Level'\n# We need to define the order explicitly to ensure 0=Normal, 1=Low, etc.\nrisk_order = ['Normal', 'Low', 'Medium', 'High']\nle = LabelEncoder()\nle.fit(risk_order)\ndf['Risk_Level_Encoded'] = le.transform(df['Risk_Level'])\n\nprint(f\"\\nLabelEncoder classes (in order): {list(le.classes_)}\")\n\n# --- 2. Define Features (X) and Target (y) ---\n\n# Define the target\ny = df['Risk_Level_Encoded']\n\n# Define the features (all columns except the original target and the new encoded target)\nX = df.drop(['Risk_Level', 'Risk_Level_Encoded'], axis=1)\n\n# **Crucial Step**: Save the column names and their order\n# This is VITAL for the simulator to build a dataframe in the exact same format\nmodel_columns = X.columns\njoblib.dump(model_columns, 'model_columns.pkl')\nprint(f\"\\nModel features (columns) saved to 'model_columns.pkl'.\")\nprint(f\"Features being used: {list(model_columns)}\")\n\n# --- 3. Train/Test Split ---\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\nprint(f\"\\nData split into training ({X_train.shape[0]} samples) and testing ({X_test.shape[0]} samples).\")\n\n# --- 4. Model Training (The \"Digital Oracle\") ---\n\nprint(\"Training the RandomForest 'Digital Oracle'...\")\n\n# Initialize the RandomForestClassifier\noracle_model = RandomForestClassifier(\n    n_estimators=100,  # A good default number of trees\n    random_state=42\n)\n\noracle_model.fit(X_train, y_train)\nprint(\"Model training complete.\")\n\n# --- 5. Model Evaluation ---\n\nprint(\"\\n--- Model Evaluation ---\")\n# Make predictions on the test set\n# Note: For the report, we need the final predicted class, not probabilities\ny_pred = oracle_model.predict(X_test)\n\n# Calculate Accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Model Accuracy on Test Set: {accuracy * 100:.2f}%\")\n\n# Generate Classification Report\n# We use le.classes_ to get the original string labels (Normal, Low, etc.)\nreport = classification_report(y_test, y_pred, target_names=le.classes_)\nprint(\"\\nClassification Report:\")\nprint(report)\n\n# --- 6. Save the Model and Label Encoder ---\n\n# Save the trained model\njoblib.dump(oracle_model, 'digital_oracle_model.pkl')\nprint(\"\\nTrained model saved as 'digital_oracle_model.pkl'\")\n\n# Save the Label Encoder\njoblib.dump(le, 'le.pkl')\nprint(\"Label encoder saved as 'le.pkl'\")\n\nprint(\"\\n'Digital Oracle' build complete. All necessary files (model, columns, encoder) are saved.\")",
      "block_group": "2bd7c8ea0c904982b606e132844a3aa2",
      "execution_count": 1,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "37d86a1b",
        "execution_start": 1763255257086,
        "execution_millis": 2705,
        "execution_context_id": "714ea9a7-d378-47be-8026-5fa12b4864af",
        "deepnote_app_block_order": 1,
        "deepnote_app_block_visible": true,
        "deepnote_app_block_group_id": null,
        "deepnote_app_is_code_hidden": true,
        "deepnote_app_is_output_hidden": false,
        "cell_id": "34debe5333f9480d82cd31ea2c9cf339",
        "deepnote_cell_type": "code"
      },
      "source": "import matplotlib.pyplot as plt\n\n# --- 1. Load Model Components ---\ntry:\n    model = joblib.load('digital_oracle_model.pkl')\n    model_columns = joblib.load('model_columns.pkl')\nexcept FileNotFoundError:\n    print(\"Error: Required model files ('digital_oracle_model.pkl' or 'model_columns.pkl') not found.\")\n    exit()\n\n# --- 2. Extract Feature Importance ---\n# RandomForestClassifier models have a feature_importances_ attribute\nfeature_importances = model.feature_importances_\n\n# --- 3. Create and Sort DataFrame ---\nimportance_df = pd.DataFrame({\n    'Feature': model_columns,\n    'Importance': feature_importances\n})\n\n# Sort by importance in descending order\nimportance_df = importance_df.sort_values(by='Importance', ascending=False)\n\nprint(\"Feature Importance calculated successfully.\")\n\n# --- 4. Visualize Results (Top 10) ---\nplt.figure(figsize=(10, 6))\ntop_n = 10\nplt.bar(importance_df['Feature'][:top_n], importance_df['Importance'][:top_n], color='teal')\nplt.xlabel('Feature')\nplt.ylabel('Importance Score (Gini)')\nplt.title(f'Top {top_n} Feature Importances for Risk Prediction')\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.savefig('feature_importance_bar_chart.png')\nplt.close()\n\nprint(\"\\nBar chart saved as 'feature_importance_bar_chart.png'.\")\n\n# --- 5. Save Results to CSV ---\nimportance_df.to_csv('feature_importances.csv', index=False)\nprint(\"Feature importance data saved to 'feature_importances.csv'.\")\nprint(\"\\nTop 5 Most Important Features:\")\nprint(importance_df.head())\n\n# --- 1. Load Data and Preprocessing (Re-training the Oracle) ---\n\ndf = pd.read_csv(\"Health_Risk_Dataset.csv\")\n\n# Drop Patient_ID\nif 'Patient_ID' in df.columns:\n    df = df.drop('Patient_ID', axis=1)\n\n# One-Hot Encoding for 'Consciousness'\ndf = pd.get_dummies(df, columns=['Consciousness'], drop_first=True)\n\n# Label Encoding for the target variable 'Risk_Level'\nrisk_order = ['Normal', 'Low', 'Medium', 'High']\nle = LabelEncoder()\nle.fit(risk_order)\ndf['Risk_Level_Encoded'] = le.transform(df['Risk_Level'])\n\n# Define Features (X) and Target (y)\ny = df['Risk_Level_Encoded']\nX = df.drop(['Risk_Level', 'Risk_Level_Encoded'], axis=1)\nmodel_columns = X.columns # Save column names again for safety\n\n# Train/Test Split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Initialize and Train the RandomForestClassifier (The Digital Oracle)\noracle_model = RandomForestClassifier(n_estimators=100, random_state=42)\noracle_model.fit(X_train, y_train)\nprint(\"RandomForest model trained successfully for feature importance calculation.\")\n\n# --- 2. Feature Importance Calculation and Visualization ---\n\n# Extract importance scores\nimportances = oracle_model.feature_importances_\nfeature_names = model_columns\n\n# Create a DataFrame for better handling and sorting\nfeature_importance_df = pd.DataFrame({\n    'Feature': feature_names,\n    'Importance': importances\n})\n\n# Sort by importance\nfeature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False).reset_index(drop=True)\n\n# Print the top features\nprint(\"\\nTop 10 Feature Importances (What drives the risk prediction?):\")\nprint(feature_importance_df.head(10))\n\n# --- 3. Visualization ---\n\n# Select the top 10 features for plotting\ntop_features = feature_importance_df.head(10)\n\nplt.figure(figsize=(10, 6))\nplt.barh(top_features['Feature'][::-1], top_features['Importance'][::-1], color='skyblue')\nplt.xlabel(\"Feature Importance Score\")\nplt.title(\"Top 10 Vital Signs Driving Health Risk Prediction\")\nplt.tight_layout()\n\n# Save the plot\nplt.savefig('feature_importance_bar_chart.png')\nprint(\"\\nFeature importance chart saved as 'feature_importance_bar_chart.png'.\")\n\n# Save the feature importance data to CSV (for reference)\nfeature_importance_df.to_csv('feature_importances.csv', index=False)\nprint(\"Feature importances saved to 'feature_importances.csv'.\")",
      "block_group": "9aafd120752b400c9235cfe064ff615e",
      "execution_count": 7,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=bdee0b07-dd93-46b8-8522-cce134092e71' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote_persisted_session": {
      "createdAt": "2025-11-16T01:18:19.099Z"
    },
    "deepnote_notebook_id": "60c1353761fe4e90bdaefdd9ef9797c0"
  }
}